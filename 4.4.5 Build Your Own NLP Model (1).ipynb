{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import state_union, stopwords\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1945-Truman.txt',\n",
       " '1946-Truman.txt',\n",
       " '1947-Truman.txt',\n",
       " '1948-Truman.txt',\n",
       " '1949-Truman.txt',\n",
       " '1950-Truman.txt',\n",
       " '1951-Truman.txt',\n",
       " '1953-Eisenhower.txt',\n",
       " '1954-Eisenhower.txt',\n",
       " '1955-Eisenhower.txt',\n",
       " '1956-Eisenhower.txt',\n",
       " '1957-Eisenhower.txt',\n",
       " '1958-Eisenhower.txt',\n",
       " '1959-Eisenhower.txt',\n",
       " '1960-Eisenhower.txt',\n",
       " '1961-Kennedy.txt',\n",
       " '1962-Kennedy.txt',\n",
       " '1963-Johnson.txt',\n",
       " '1963-Kennedy.txt',\n",
       " '1964-Johnson.txt',\n",
       " '1965-Johnson-1.txt',\n",
       " '1965-Johnson-2.txt',\n",
       " '1966-Johnson.txt',\n",
       " '1967-Johnson.txt',\n",
       " '1968-Johnson.txt',\n",
       " '1969-Johnson.txt',\n",
       " '1970-Nixon.txt',\n",
       " '1971-Nixon.txt',\n",
       " '1972-Nixon.txt',\n",
       " '1973-Nixon.txt',\n",
       " '1974-Nixon.txt',\n",
       " '1975-Ford.txt',\n",
       " '1976-Ford.txt',\n",
       " '1977-Ford.txt',\n",
       " '1978-Carter.txt',\n",
       " '1979-Carter.txt',\n",
       " '1980-Carter.txt',\n",
       " '1981-Reagan.txt',\n",
       " '1982-Reagan.txt',\n",
       " '1983-Reagan.txt',\n",
       " '1984-Reagan.txt',\n",
       " '1985-Reagan.txt',\n",
       " '1986-Reagan.txt',\n",
       " '1987-Reagan.txt',\n",
       " '1988-Reagan.txt',\n",
       " '1989-Bush.txt',\n",
       " '1990-Bush.txt',\n",
       " '1991-Bush-1.txt',\n",
       " '1991-Bush-2.txt',\n",
       " '1992-Bush.txt',\n",
       " '1993-Clinton.txt',\n",
       " '1994-Clinton.txt',\n",
       " '1995-Clinton.txt',\n",
       " '1996-Clinton.txt',\n",
       " '1997-Clinton.txt',\n",
       " '1998-Clinton.txt',\n",
       " '1999-Clinton.txt',\n",
       " '2000-Clinton.txt',\n",
       " '2001-GWBush-1.txt',\n",
       " '2001-GWBush-2.txt',\n",
       " '2002-GWBush.txt',\n",
       " '2003-GWBush.txt',\n",
       " '2004-GWBush.txt',\n",
       " '2005-GWBush.txt',\n",
       " '2006-GWBush.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_union.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's analyze Eisenhower and Kennedy\n",
    "eisenhower = state_union.raw('1953-Eisenhower.txt')\n",
    "kennedy = state_union.raw('1962-Kennedy.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for standard text cleaning.\n",
    "def text_cleaner(text):\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'.  Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "    \n",
    "eisenhower = text_cleaner(eisenhower)\n",
    "kennedy = text_cleaner(kennedy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SpaCy\n",
    "nlp = spacy.load('en')\n",
    "eisenhower_doc = nlp(eisenhower)\n",
    "kennedy_doc = nlp(kennedy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(PRESIDENT, DWIGHT, D., EISENHOWER, 'S)</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(ANNUAL, MESSAGE, TO, THE, CONGRESS, ON, THE, ...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Mr., President, ,, Mr., Speaker, ,, Members, ...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(I, welcome, the, honor, of, appearing, before...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(It, is, manifestly, the, joint, purpose, of, ...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0           1\n",
       "0            (PRESIDENT, DWIGHT, D., EISENHOWER, 'S)  Eisenhower\n",
       "1  (ANNUAL, MESSAGE, TO, THE, CONGRESS, ON, THE, ...  Eisenhower\n",
       "2  (Mr., President, ,, Mr., Speaker, ,, Members, ...  Eisenhower\n",
       "3  (I, welcome, the, honor, of, appearing, before...  Eisenhower\n",
       "4  (It, is, manifestly, the, joint, purpose, of, ...  Eisenhower"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group into sentences.\n",
    "eisenhower_sents = [[sent, 'Eisenhower'] for sent in eisenhower_doc.sents]\n",
    "kennedy_sents = [[sent, \"Kennedy\"] for sent in kennedy_doc.sents]\n",
    "\n",
    "# Combine the sentences from the two novels into one data frame.\n",
    "sentences = pd.DataFrame(eisenhower_sents + kennedy_sents)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eisenhower speech length: 7726\n",
      "Kennedy speech length: 7578\n"
     ]
    }
   ],
   "source": [
    "# how long are their speeches?\n",
    "print('Eisenhower speech length:', len(eisenhower_doc))\n",
    "print('Kennedy speech length:', len(kennedy_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRESIDENT DWIGHT D. EISENHOWER'S ANNUAL MESSAGE TO THE CONGRESS ON THE STATE OF THE UNION February 2, 1953 Mr. President, Mr. Speaker, Members of the Eighty-third Congress: I welcome the honor of appearing before you to deliver my first message to the Congress. It is manifestly the joint purpose of the congressional leadership and of this administration to justify the summons to governmental responsibility issued last November by the American people. The grand labors of this leadership will involve: Application of America's influence in world affairs with such fortitude\n",
      "PRESIDENT JOHN F. KENNEDY'S ANNUAL ADDRESS TO A JOINT SESSION OF CONGRESS ON THE STATE OF THE UNION This week we begin anew our joint and separate efforts to build the American future. But, sadly, we build without a man who linked a long past with the present and looked strongly to the future. \"Mister Sam\" Rayburn is gone. Neither this House nor the Nation is the same without him. Members of the Congress, the Constitution makes us not rivals for power but partners for progress. We are all\n"
     ]
    }
   ],
   "source": [
    "# check excerpts for any other cleaning needed\n",
    "print(eisenhower_doc[:100])\n",
    "print(kennedy_doc[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 2000 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(2000)]\n",
    "    \n",
    "\n",
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 500 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the bags.\n",
    "eisenhowerwords = bag_of_words(eisenhower_doc)\n",
    "kennedywords = bag_of_words(kennedy_doc)\n",
    "\n",
    "# Combine bags to create a set of unique words.\n",
    "common_words = set(eisenhowerwords + kennedywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confession</th>\n",
       "      <th>survive</th>\n",
       "      <th>grave</th>\n",
       "      <th>counsel</th>\n",
       "      <th>hear</th>\n",
       "      <th>acceptable</th>\n",
       "      <th>emphasize</th>\n",
       "      <th>ability</th>\n",
       "      <th>communism</th>\n",
       "      <th>nature</th>\n",
       "      <th>...</th>\n",
       "      <th>machine</th>\n",
       "      <th>entire</th>\n",
       "      <th>safety</th>\n",
       "      <th>transcend</th>\n",
       "      <th>above</th>\n",
       "      <th>ignore</th>\n",
       "      <th>necessitate</th>\n",
       "      <th>nonpartisan</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(PRESIDENT, DWIGHT, D., EISENHOWER, 'S)</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(ANNUAL, MESSAGE, TO, THE, CONGRESS, ON, THE, ...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Mr., President, ,, Mr., Speaker, ,, Members, ...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(I, welcome, the, honor, of, appearing, before...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(It, is, manifestly, the, joint, purpose, of, ...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2269 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  confession survive grave counsel hear acceptable emphasize ability  \\\n",
       "0          0       0     0       0    0          0         0       0   \n",
       "1          0       0     0       0    0          0         0       0   \n",
       "2          0       0     0       0    0          0         0       0   \n",
       "3          0       0     0       0    0          0         0       0   \n",
       "4          0       0     0       0    0          0         0       0   \n",
       "\n",
       "  communism nature     ...     machine entire safety transcend above ignore  \\\n",
       "0         0      0     ...           0      0      0         0     0      0   \n",
       "1         0      0     ...           0      0      0         0     0      0   \n",
       "2         0      0     ...           0      0      0         0     0      0   \n",
       "3         0      0     ...           0      0      0         0     0      0   \n",
       "4         0      0     ...           0      0      0         0     0      0   \n",
       "\n",
       "  necessitate nonpartisan                                      text_sentence  \\\n",
       "0           0           0            (PRESIDENT, DWIGHT, D., EISENHOWER, 'S)   \n",
       "1           0           0  (ANNUAL, MESSAGE, TO, THE, CONGRESS, ON, THE, ...   \n",
       "2           0           0  (Mr., President, ,, Mr., Speaker, ,, Members, ...   \n",
       "3           0           0  (I, welcome, the, honor, of, appearing, before...   \n",
       "4           0           0  (It, is, manifestly, the, joint, purpose, of, ...   \n",
       "\n",
       "  text_source  \n",
       "0  Eisenhower  \n",
       "1  Eisenhower  \n",
       "2  Eisenhower  \n",
       "3  Eisenhower  \n",
       "4  Eisenhower  \n",
       "\n",
       "[5 rows x 2269 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create bow features \n",
    "bow = bow_features(sentences, common_words)\n",
    "bow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentences\n",
    "eisenhower = state_union.sents('1953-Eisenhower.txt')\n",
    "kennedy = state_union.sents('1962-Kennedy.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists\n",
    "eisenhower_list = [\" \".join(sent) for sent in eisenhower]\n",
    "kennedy_list = [\" \".join(sent) for sent in kennedy]\n",
    "together = eisenhower_list + kennedy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 1090\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#X_train, X_test = train_test_split(together, test_size=0.4, random_state=0)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, # drop words that occur in more than half the paragraphs\n",
    "                             min_df=2, # only use words that appear at least twice\n",
    "                             stop_words='english', \n",
    "                             lowercase=True, #convert everything to lower case (since Alice in Wonderland has the HABIT of CAPITALIZING WORDS for EMPHASIS)\n",
    "                             use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
    "                             norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "                             smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
    "                            )\n",
    "\n",
    "\n",
    "#Applying the vectorizer\n",
    "together_tfidf=vectorizer.fit_transform(together)\n",
    "print(\"Number of features: %d\" % together_tfidf.get_shape()[1])\n",
    "\n",
    "tfidf = vectorizer.fit_transform(together).tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These two texts, even though just a few years apart, are not highly correlated. There could be many reasons for this, but perhaps it's a shift in party in the White House? Or, different events at the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(382, 2267) (382,)\n",
      "BoW Training set score: 0.9921465968586387\n",
      "BoW Test set score: 0.7607843137254902\n",
      "BoW Predictions: ['Kennedy' 'Eisenhower' 'Kennedy' 'Kennedy' 'Eisenhower']\n",
      "Cross-validated scores: [0.6015625  0.6015625  0.6875     0.62204724 0.64285714]\n",
      "Avg. Score  0.6311058773903262\n",
      "\n",
      "TFIDF Training set score: 0.9381720430107527\n",
      "TFIDF Test set score: 0.678714859437751\n",
      "Predictions: ['Eisenhower' 'Eisenhower' 'Kennedy' 'Eisenhower' 'Eisenhower']\n",
      "Cross-validated scores: [0.464      0.568      0.60483871 0.62096774 0.62601626]\n",
      "Avg. Score  0.576764542355101\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "\n",
    "# Set X, y and train, test, split\n",
    "y = bow['text_source']\n",
    "X = np.array(bow.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=0)\n",
    "\n",
    "# Logistic Regression Model with BoW\n",
    "lrb = LogisticRegression()\n",
    "model = lrb.fit(X_train, y_train)\n",
    "pred = lrb.predict(X_test)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('BoW Training set score:', lrb.score(X_train, y_train))\n",
    "print('BoW Test set score:', lrb.score(X_test, y_test))\n",
    "print('BoW Predictions:', pred[0:5])\n",
    "\n",
    "#5 fold Cross Validation\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "print('Cross-validated scores:', scores)\n",
    "print('Avg. Score ', np.mean(cross_val_score(lrb, X, y, cv=5)))\n",
    "\n",
    "\n",
    "# Tfidf\n",
    "X_tfidf = tfidf\n",
    "y_tfidf = ['Eisenhower']*len(eisenhower_list) + ['Kennedy']*len(kennedy_list)\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X_tfidf, \n",
    "                                                    y_tfidf,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=0)\n",
    "# Logistic Regression Model with TFIDF\n",
    "lrt = LogisticRegression()\n",
    "model = lrt.fit(X2_train, y2_train)\n",
    "pred = lrt.predict(X2_test)\n",
    "print('\\nTFIDF Training set score:', lrt.score(X2_train, y2_train))\n",
    "print('TFIDF Test set score:', lrt.score(X2_test, y2_test))\n",
    "print('Predictions:', pred[0:5])\n",
    "\n",
    "#5 fold Cross Validation\n",
    "scores = cross_val_score(model, X_tfidf, y_tfidf, cv=5)\n",
    "print('Cross-validated scores:', scores)\n",
    "print('Avg. Score ', np.mean(cross_val_score(lrt, X_tfidf, y_tfidf, cv=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9738219895287958\n",
      "Test set score: 0.6745098039215687\n",
      "Predictions: ['Eisenhower' 'Eisenhower' 'Kennedy' 'Kennedy' 'Eisenhower']\n",
      "Cross-validated scores: [0.6484375  0.53125    0.7109375  0.58267717 0.61904762]\n",
      "Avg. Score  0.6263931852268466\n",
      "\n",
      "TFIDF Training set score: 0.9838709677419355\n",
      "TFIDF Test set score: 0.6506024096385542\n",
      "Predictions: ['Kennedy' 'Eisenhower' 'Eisenhower' 'Eisenhower' 'Eisenhower']\n",
      "Cross-validated scores: [0.504      0.528      0.57258065 0.60483871 0.57723577]\n",
      "Avg. Score  0.5735518489378443\n"
     ]
    }
   ],
   "source": [
    "#Import\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Random Forest Model with BoW\n",
    "rfcb = RandomForestClassifier()\n",
    "model = rfcb.fit(X_train, y_train)\n",
    "pred = rfcb.predict(X_test)\n",
    "print('Training set score:', rfcb.score(X_train, y_train))\n",
    "print('Test set score:', rfcb.score(X_test, y_test))\n",
    "print('Predictions:', pred[0:5])\n",
    "\n",
    "#5 fold cross validation\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "print('Cross-validated scores:', scores)\n",
    "print('Avg. Score ', np.mean(cross_val_score(rfcb, X, y, cv=5)))\n",
    "\n",
    "# Random Forest Model with TFIDF\n",
    "rfct = RandomForestClassifier()\n",
    "model = rfct.fit(X2_train, y2_train)\n",
    "pred = rfct.predict(X2_test)\n",
    "print('\\nTFIDF Training set score:', rfct.score(X2_train, y2_train))\n",
    "print('TFIDF Test set score:', rfct.score(X2_test, y2_test))\n",
    "print('Predictions:', pred[0:5])\n",
    "\n",
    "#5 fold Cross Validation\n",
    "scores = cross_val_score(model, X_tfidf, y_tfidf, cv=5)\n",
    "print('Cross-validated scores:', scores)\n",
    "print('Avg. Score ', np.mean(cross_val_score(rfct, X_tfidf, y_tfidf, cv=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.8141361256544503\n",
      "Test set score: 0.6745098039215687\n",
      "Cross-validated scores: [0.5859375  0.6328125  0.6875     0.61417323 0.6031746 ]\n",
      "Avg. Score  0.624719566304212\n",
      "\n",
      "TFIDF Training set score: 0.782258064516129\n",
      "TFIDF Test set score: 0.6305220883534136\n",
      "Predictions: ['Kennedy' 'Eisenhower' 'Eisenhower' 'Eisenhower' 'Kennedy']\n",
      "Cross-validated scores: [0.528      0.56       0.62903226 0.59677419 0.58536585]\n",
      "Avg. Score  0.5798344610542879\n"
     ]
    }
   ],
   "source": [
    "#import\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#Our XGBoost Classifier\n",
    "clfb = XGBClassifier()\n",
    "model= clfb.fit(X_train, y_train)\n",
    "print('Training set score:', clfb.score(X_train, y_train))\n",
    "print('Test set score:', clfb.score(X_test, y_test))\n",
    "\n",
    "#5 fold cross validation\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "print('Cross-validated scores:', scores)\n",
    "print('Avg. Score ', np.mean(cross_val_score(clfb, X, y, cv=5)))\n",
    "\n",
    "# Random Forest Model with TFIDF\n",
    "clft = XGBClassifier()\n",
    "model = clft.fit(X2_train, y2_train)\n",
    "pred = clft.predict(X2_test)\n",
    "print('\\nTFIDF Training set score:', clft.score(X2_train, y2_train))\n",
    "print('TFIDF Test set score:', clft.score(X2_test, y2_test))\n",
    "print('Predictions:', pred[0:5])\n",
    "\n",
    "#5 fold Cross Validation\n",
    "scores = cross_val_score(model, X_tfidf, y_tfidf, cv=5)\n",
    "print('Cross-validated scores:', scores)\n",
    "print('Avg. Score ', np.mean(cross_val_score(clft, X_tfidf, y_tfidf, cv=5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9895287958115183\n",
      "Test set score: 0.6862745098039216\n",
      "Cross-validated scores: [0.59375    0.625      0.703125   0.60629921 0.57936508]\n",
      "Avg. Score  0.6230703583927009\n",
      "\n",
      "TFIDF Training set score: 0.9895287958115183\n",
      "TFIDF Test set score: 0.6901960784313725\n",
      "Predictions: ['Kennedy' 'Eisenhower' 'Kennedy' 'Eisenhower' 'Eisenhower']\n",
      "Cross-validated scores: [0.496      0.56       0.63709677 0.61290323 0.6097561 ]\n",
      "Avg. Score  0.5831512195121952\n"
     ]
    }
   ],
   "source": [
    "# We'll make 500 iterations, use 2-deep trees, and set our loss function.\n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 2,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clfb = ensemble.GradientBoostingClassifier(**params)\n",
    "model= clfb.fit(X_train, y_train)\n",
    "print('Training set score:', clfb.score(X_train, y_train))\n",
    "print('Test set score:', clfb.score(X_test, y_test))\n",
    "\n",
    "#5 fold cross validation\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "print('Cross-validated scores:', scores)\n",
    "print('Avg. Score ', np.mean(cross_val_score(clfb, X, y, cv=5)))\n",
    "\n",
    "# Random Forest Model with TFIDF\n",
    "clft = ensemble.GradientBoostingClassifier(**params)\n",
    "model = clft.fit(X2_train, y2_train)\n",
    "pred = clft.predict(X2_test)\n",
    "print('\\nTFIDF Training set score:', clft.score(X2_train, y2_train))\n",
    "print('TFIDF Test set score:', clft.score(X2_test, y2_test))\n",
    "print('Predictions:', pred[0:5])\n",
    "\n",
    "#5 fold Cross Validation\n",
    "scores = cross_val_score(model, X_tfidf, y_tfidf, cv=5)\n",
    "print('Cross-validated scores:', scores)\n",
    "print('Avg. Score ', np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increase Accuracy by 5% on Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 3000 most common words and add in punctuation.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(4000)]\n",
    "    \n",
    "\n",
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 500 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df\n",
    "\n",
    "# Set up the bags.\n",
    "eisenhowerwords = bag_of_words(eisenhower_doc)\n",
    "kennedywords = bag_of_words(kennedy_doc)\n",
    "\n",
    "# Combine bags to create a set of unique words.\n",
    "common_words = set(eisenhowerwords + kennedywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confession</th>\n",
       "      <th>survive</th>\n",
       "      <th>grave</th>\n",
       "      <th>counsel</th>\n",
       "      <th>hear</th>\n",
       "      <th>acceptable</th>\n",
       "      <th>emphasize</th>\n",
       "      <th>ability</th>\n",
       "      <th>communism</th>\n",
       "      <th>nature</th>\n",
       "      <th>...</th>\n",
       "      <th>machine</th>\n",
       "      <th>entire</th>\n",
       "      <th>safety</th>\n",
       "      <th>transcend</th>\n",
       "      <th>above</th>\n",
       "      <th>ignore</th>\n",
       "      <th>necessitate</th>\n",
       "      <th>nonpartisan</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(PRESIDENT, DWIGHT, D., EISENHOWER, 'S)</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(ANNUAL, MESSAGE, TO, THE, CONGRESS, ON, THE, ...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Mr., President, ,, Mr., Speaker, ,, Members, ...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(I, welcome, the, honor, of, appearing, before...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(It, is, manifestly, the, joint, purpose, of, ...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2269 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  confession survive grave counsel hear acceptable emphasize ability  \\\n",
       "0          0       0     0       0    0          0         0       0   \n",
       "1          0       0     0       0    0          0         0       0   \n",
       "2          0       0     0       0    0          0         0       0   \n",
       "3          0       0     0       0    0          0         0       0   \n",
       "4          0       0     0       0    0          0         0       0   \n",
       "\n",
       "  communism nature     ...     machine entire safety transcend above ignore  \\\n",
       "0         0      0     ...           0      0      0         0     0      0   \n",
       "1         0      0     ...           0      0      0         0     0      0   \n",
       "2         0      0     ...           0      0      0         0     0      0   \n",
       "3         0      0     ...           0      0      0         0     0      0   \n",
       "4         0      0     ...           0      0      0         0     0      0   \n",
       "\n",
       "  necessitate nonpartisan                                      text_sentence  \\\n",
       "0           0           0            (PRESIDENT, DWIGHT, D., EISENHOWER, 'S)   \n",
       "1           0           0  (ANNUAL, MESSAGE, TO, THE, CONGRESS, ON, THE, ...   \n",
       "2           0           0  (Mr., President, ,, Mr., Speaker, ,, Members, ...   \n",
       "3           0           0  (I, welcome, the, honor, of, appearing, before...   \n",
       "4           0           0  (It, is, manifestly, the, joint, purpose, of, ...   \n",
       "\n",
       "  text_source  \n",
       "0  Eisenhower  \n",
       "1  Eisenhower  \n",
       "2  Eisenhower  \n",
       "3  Eisenhower  \n",
       "4  Eisenhower  \n",
       "\n",
       "[5 rows x 2269 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create bow features \n",
    "bow_inc = bow_features(sentences, common_words)\n",
    "bow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(382, 2279) (382,)\n",
      "BoW Training set score: 0.9921465968586387\n",
      "BoW Test set score: 0.7607843137254902\n",
      "BoW Predictions: ['Kennedy' 'Eisenhower' 'Kennedy' 'Kennedy' 'Eisenhower']\n",
      "Cross-validated scores: [0.67692308 0.63076923 0.69230769 0.71875    0.73015873 0.68253968\n",
      " 0.63492063 0.66666667 0.6984127  0.6984127 ]\n",
      "Avg. Score  0.6829861111111111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Set X, y and train, test, split\n",
    "y2 = bow_inc['text_source']\n",
    "X2 = np.array(bow_inc.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, \n",
    "                                                    y2,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=0)\n",
    "\n",
    "# Logistic Regression Model with GridSearchCV on BoW\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }\n",
    "lrb2 = GridSearchCV(LogisticRegression(penalty='l2', \n",
    "                                       random_state=42,\n",
    "                                       dual=True,\n",
    "                                       class_weight=None), param_grid)\n",
    "model2 = lrb2.fit(X2_train, y2_train)\n",
    "pred = lrb2.predict(X2_test)\n",
    "print(X2_train.shape, y2_train.shape)\n",
    "print('BoW Training set score:', lrb2.score(X2_train, y2_train))\n",
    "print('BoW Test set score:', lrb2.score(X2_test, y2_test))\n",
    "print('BoW Predictions:', pred[0:5])\n",
    "#10 fold Cross Validation\n",
    "scores = cross_val_score(model2, X2, y2, cv=10)\n",
    "print('Cross-validated scores:', scores)\n",
    "print('Avg. Score ', np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Grid Search, tuning parameters and Cross Validating with 10 folds was the best solution to increase by 5%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
