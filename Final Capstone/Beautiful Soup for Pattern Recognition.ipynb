{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET CONNECTION FROM THE LOCAL POOL\n",
      "PRAGMA foreign_keys = false\n",
      "BEGIN IMMEDIATE TRANSACTION\n",
      "SELECT \"Job\".\"id\", \"Job\".\"title\", \"Job\".\"job_description\", \"Job\".\"job_class\"\n",
      "FROM \"Job\" \"Job\"\n",
      "WHERE 0 = 1\n",
      "\n",
      "COMMIT\n",
      "PRAGMA foreign_keys = true\n",
      "CLOSE CONNECTION\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import urljoin\n",
    "page = requests.get('https://www.indeed.com/jobs?q=%22pattern+recognition%22&start=')\n",
    "from time import sleep\n",
    "import time\n",
    "from random import randint\n",
    "from pony_main import *\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "from IPython.display import clear_output\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET CONNECTION FROM THE LOCAL POOL\n",
      "BEGIN IMMEDIATE TRANSACTION\n",
      "INSERT INTO \"Job\" (\"title\", \"job_description\", \"job_class\") VALUES (?, ?, ?)\n",
      "['<h3 class=\"icl-u-xs-mb--xs icl-u-xs-mt--none jobsearch-JobInfoHeader-title\">Software Engineer, Sr Principal</h3>', '<div class=\"jobsearch-JobComponent-description icl-u-xs-mt--md\"><div><p><b>Job Description</b></p><p></p><p><b>\\nAbout the position:</b></p><p>\\nThe project is a joint, R&amp;D effort between the client groups to develop a prototype mass analytic system that will enable users to have sophisticated interactions with large volumes of disparate data, either by presenting the data visually or by asking questions more complex than a Boolean query would allow. The program will feature an immense, spreadsheet-like - analytic fabric- of building blocks that will make it easier to integrate with and exploit data from multiple capabilities, such as knowledge bases, natural language processing (NLP) stacks, latent semantic indexing, and visualization tools. You will serve as a recognized company authority performing system and subsystem definition, preliminary and detailed design, design implementation, and subsystem and system integration and tests for a system. You will participates in software requirement review, preliminary and critical design, integration readiness review, and software acceptance review.</p><p></p><p><b>\\nWhat You’ll Get to Do:</b></p><p>\\nYou will perform all aspects of data processing and analysis - including extraction, transformation, and load (ETL) - to derive valuable insights from the customer\\'s data of all types (structured, unstructured, and semi-structured, but mainly unstructured). You will work effectively with the customer help identify patterns, anomalies, and regularities in the data or by applying advanced research skills beyond what the traditional analyst would be expected to use. You will Be a key data expert and would be expected to participate in a wide variety of internal and external for a to advance the analytic tradecraft, improve the capabilities of the project tools, and stay current on the latest trends involving data, such as XML schema changes. You would also be expected to become a knowledge engineer and be capable of developing the requisite ontologies, taxonomies, lexicons, data specifications, and/or common metadata standards for the project tools and for effective data exchanges with partner systems.\\n</p><p></p><p><b>You’ll Bring These Qualifications:</b></p><ul><li>\\nYou would be expected to prepare and deliver both technical and high-level briefings on data-related matters that are relevant to the project, including briefings with proposed changes to optimize project use of the data.</li><li>\\nYou would be expected to possess and deliver exceptionally strong technical and ETL skills, because the data-related functions are central to the project\\'s overall success.</li><li>\\nThe ETL tasks encompass the data being cleansed, segmented, normalized, reassembled, harmonized (semantic mediation) and exploited using a variety of extraction and visualization tools.</li><li>\\nYou would be expected to participate in the evaluation of new tools for the project, and those tools could range in type from extraction tools to highly sophisticated advanced analytic tools.</li><li>\\nYou would be expected to possess a natural desire to keep abreast of the latest tools (open source, customer\\'s Proprietary (Equipment, Software), and COTS) for data science/data architecture so that you could work effectively with other incubating technologies and help the project identify better capabilities</li></ul><p></p><p><b>\\nRequired Skills:</b></p><ul><li>\\nDemonstrated experience interpreting rich data sources, merge data sources together, ensure consistency of data-sets, create visualizations to aid in understanding data, present and communicate the data insights/findings to specialists and scientists in their team and if required to a naive audience. This includes collaborating with non-technical audiences and/or analysts to extract meaning from data and to create data products.</li><li>\\nDemonstrated experience of developing analysis and advanced research products by incorporating varying data elements and by building on techniques and theories from many fields, including signal processing, mathematics, probability models, machine learning, statistical learning, computer programming, data engineering, pattern recognition and learning, visualization, uncertainty modeling, data warehousing, and high performance computing.</li><li>\\nDemonstrated experience showing, problem-solving skills, flexibility, technical acumen, resourcefulness.</li><li>\\nDemonstrated experience with Tableau dashboards and Impala tables</li><li>\\nHolds a Bachelor\\'s degree or equivalent in computer science, data science, data architecture, data analysis, or related field of study.</li><li>\\nDemonstrated experience of using SQL</li></ul><p></p><p><b>\\nDesired Skills:</b></p><ul><li>\\nDemonstrated ability of using data science techniques to conduct research across various domains, including the political science, economics, social sciences and the humanities.</li><li>\\nHolds a Master\\'s degree or Ph.D in data science, data architecture, data analysis, or related field of study.</li><li>\\nDemonstrated experience creating a data model that effectively integrates mission needs with underlying data structures. This includes experience with developing a complete data taxonomy, ontology, or metadata standard from scratch as well as merging two data specifications from differing projects.</li><li>\\nDemonstrated experience of being embedded with an the Sponsor\\'s mission customer to exploit data science techniques in a collaborative manner, including briefing the mission customer and its analysts.</li><li>\\nDemonstrated experience of working with conventional tools for Big Data and Data Science, such as Big Data manipulation tools (e.g. Hadoop, Pig, Hive, Python) or statistical analysis tools (e.g. SAS, SPSS, R), or data warehouse and loading tools (e.g. Teradata, Informatica).</li><li>\\nDemonstrated experience with 1010data Appliance, entity extraction tools (e.g. Aerotext, NetOwl), and/or Digital Reasoning Synthesis (DRS), or other similar advanced computing systems, such as those involving natural language processing or advanced analytics.</li><li>\\nDemonstrated experience with designing, testing and deploying Tableau dashboards and/or other user interface (U/I) features for data scientists or analysts with this client or customer\\'s partners.</li><li>\\nDemonstrated experience with client\\'s or customer\\'s partners data architecture constructs, including metadata standards, PUBS-XML, NewsML, or comparable XML formats.</li><li>\\nDemonstrated and recognized expertise in the field of data science, such as by authoring papers on data science, speaking at conventions, or leading other initiatives in data science, machine learning, or related fields.</li><li>\\nMinimum of two years of demonstrated experience as a data expert (data analyst, data scientist, data architect) with client or r\\'s partners.</li></ul><p></p><p><b>\\nEducation and Experience Requirements:</b></p><p>\\nCandidate must have one of the following:</p><ul><li>\\n12 Years of job related experience and High School/GED diploma</li><li>\\n10 Years of job related experience and Associate degree</li><li>\\n8 Years of job related experience and Bachelor’s degree</li><li>\\n6 Years of job related experience and Master’s degree</li><li>\\n4 Years of job related experience and Doctorate</li></ul><p></p><p><b>\\nWhat We Can Offer You:</b></p><ul><li>\\nWe’ve been named a Best Place to Work by the Washington Post.</li><li>\\nOur employees value the flexibility at CACI that allows them to balance quality work and their personal lives.</li><li>\\nWe offer competitive benefits and learning and development opportunities.</li><li>\\nWe are mission-oriented and ever vigilant in aligning our solutions with the nation’s highest priorities.</li><li>\\nFor over 55 years, the principles of CACI’s unique, character-based culture have been the driving force behind our success.</li></ul><p></p><p><b>\\nJob Location</b></p><p>\\nUS-Chantilly-VA-VIRGINIA SUBURBAN</p><br/>\\n<p></p>\\n<p>\\nCACI employs a diverse range of talent to create an environment that fuels innovation and fosters continuous improvement and success. At CACI, you will have the opportunity to make an immediate impact by providing information solutions and services in support of national security missions and government transformation for Intelligence, Defense, and Federal Civilian customers. CACI is proud to provide dynamic careers for employees worldwide. CACI is an Equal Opportunity Employer - Females/Minorities/Protected Veterans/Individuals with Disabilities.</p></div></div>', 'Pattern Recognition']\n",
      "\n",
      "COMMIT\n",
      "RELEASE CONNECTION\n"
     ]
    }
   ],
   "source": [
    "starts = list(range(40, 1000, 10))\n",
    "requests = 0\n",
    "start = time.time()\n",
    "\n",
    "baseurl = 'https://www.indeed.com'\n",
    "\n",
    "patternrec_jobs = []\n",
    "for start in starts:\n",
    "    my_urls = ('https://www.indeed.com/jobs?q=%22pattern+recognition%22&start=' + str(start),)\n",
    "    my_url = my_urls[0]\n",
    "    for my_url in my_urls:\n",
    "        uClient = urlopen(my_url)\n",
    "        html_input = uClient.read()\n",
    "        uClient.close()\n",
    "        soup = BeautifulSoup(html_input, \"html.parser\")\n",
    "        cards = soup.findAll('div', {'class':'jobsearch-SerpJobCard'})\n",
    "        it = iter(cards)\n",
    "        next(it) # ads\n",
    "        next(it) # ads\n",
    "        for curr in it: \n",
    "\n",
    "            try:\n",
    "                link = curr.find('h2').find('a', href=True)['href']\n",
    "            except:\n",
    "                print('missing content @' + baseurl + str('href')) \n",
    "            try:\n",
    "                with urlopen(baseurl + link) as uClient:\n",
    "                    list_url = uClient.read()\n",
    "            except:\n",
    "                print('There was an error with the request')\n",
    "            listing = BeautifulSoup(list_url, 'html.parser')\n",
    "            title = listing.find('h3', \n",
    "                            {'class': 'icl-u-xs-mb--xs icl-u-xs-mt--none jobsearch-JobInfoHeader-title'})\n",
    "            if not title:\n",
    "                    print('missing content @ ' + baseurl + link)\n",
    "            body = listing.find('div', \n",
    "                            {'class': 'jobsearch-JobComponent-description icl-u-xs-mt--md'}\n",
    "                            )\n",
    "            if not body:\n",
    "                print('missing content @ ' + baseurl + link)\n",
    "            requests += 1\n",
    "            sleep(randint(8,10))\n",
    "            end = time.time()\n",
    "            #print(\"Done in\", end - start, \"seconds\")\n",
    "            print('Request: {}; Frequency: {} requests/s'.format(requests, requests/end))\n",
    "            clear_output(wait = True)\n",
    "            with db_session:\n",
    "                Job(title=str(title), \n",
    "                job_description=str(body), \n",
    "                job_class='Pattern Recognition')\n",
    "            clear_output(wait = True)\n",
    "            #posting = {\n",
    "                #'title':title,\n",
    "                #'job_description':body\n",
    "                #}\n",
    "            #patternrec_jobs.append(posting)\n",
    "            #pony as a context manager\n",
    "            #with pny.db_session:\n",
    "                #title = title,\n",
    "                #job_description = body\n",
    "                #job_class = 'Pattern Recognition'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
