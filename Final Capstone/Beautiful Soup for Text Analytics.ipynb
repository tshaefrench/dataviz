{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET CONNECTION FROM THE LOCAL POOL\n",
      "PRAGMA foreign_keys = false\n",
      "BEGIN IMMEDIATE TRANSACTION\n",
      "SELECT \"Job\".\"id\", \"Job\".\"title\", \"Job\".\"job_description\", \"Job\".\"job_class\"\n",
      "FROM \"Job\" \"Job\"\n",
      "WHERE 0 = 1\n",
      "\n",
      "COMMIT\n",
      "PRAGMA foreign_keys = true\n",
      "CLOSE CONNECTION\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import urljoin\n",
    "page = requests.get('https://www.indeed.com/jobs?q=\"text+analytics\"&start=')\n",
    "from time import sleep\n",
    "import time\n",
    "from random import randint\n",
    "from pony_main import *\n",
    "from pony.orm import *\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "from IPython.display import clear_output\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET CONNECTION FROM THE LOCAL POOL\n",
      "BEGIN IMMEDIATE TRANSACTION\n",
      "INSERT INTO \"Job\" (\"title\", \"job_description\", \"job_class\") VALUES (?, ?, ?)\n",
      "['<h3 class=\"icl-u-xs-mb--xs icl-u-xs-mt--none jobsearch-JobInfoHeader-title\">Data Scientist</h3>', '<div class=\"jobsearch-JobComponent-description icl-u-xs-mt--md\"><div><p><b>Requisition ID:</b><br/>\\nreq5121</p>\\n<p><b>Job Title:</b><br/>\\nData Scientist</p>\\n<p><b>Number of Openings:</b><br/>\\n6</p>\\n<p><b>Job Category:</b><br/>\\nProfessional/Technical\\n</p><p><b>Employment Type:</b><br/>\\nRegular Full-Time</p>\\n<p><b>Shift:</b><br/>\\nFirst</p>\\n<p><b>Weekends:</b><br/>\\nNot Required</p>\\n<p><b>Location:</b><br/>\\nBloomington, IL, Atlanta, GA, Dallas, TX, and Phoenix, AZ</p>\\n<p><b>Duties and Responsibilities:</b><br/>\\n</p><ul><li>Performs improved visual representation of data to allow clearer communication, viewer engagement and faster/better decision-making</li><li>\\nInvestigates, recommends, and initiates acquisition of new data resources from internal and external sources</li><li>\\nWorks with IT teams to support data collection, integration, and retention requirements based on business need</li><li>\\nIdentifies critical and emerging technologies that will support and extend quantitative analytic capabilities</li><li>\\nManages work efforts which require the use of sophisticated project planning techniques</li><li>\\nApplies a wide application of complex principles, theories and concepts in a specific field to provide solutions to a wide range of difficult problems</li><li>\\nDevelops and maintains an effective network of both scientific and business contacts/knowledge obtaining relevant information and intelligence around the market and emergent opportunities</li><li>\\nContributes data to State Farm\\'s internal and external publications, write articles for leading journals and participate in academic and industry conferences</li></ul>\\n<ul><li>Collaborates with business subject matter experts to select relevant sources of information</li><li>\\nDevelop breadth of knowledge in programming (R, Python), Descriptive, Inferential, and Experimental Design statistics, advanced mathematics, and database functionality (SQL, Hadoop)</li><li>\\nDevelop expertise with multiple machine learning algorithms and data science techniques, such as exploratory data analysis, generative and discriminative predictive modeling, graph theory, recommender systems, text analytics, computer vision, deep learning, optimization and validation</li><li>\\nDevelop expertise with State Farm datasets, data repositories, and data movement processes</li><li>\\nAssists on projects/requests and may lead specific tasks within the project scope</li><li>\\nPrepares and manipulates data for use in development of statistical models</li><li>\\nDevelops fundamental understanding of insurance and financial services operations and uses this knowledge in decision making</li></ul><p></p>\\n<p><b>Additional Details:</b><br/>\\n</p><p>\\nSpecial skills needed:</p><p>\\nFor over 95 years, data has been key to State Farm. As a member of our data science team with the Enterprise Data &amp; Analytics department under our Chief Data &amp; Analytics Officer, you will work across the organization to solve business problems and help achieve business strategies. You will employ sophisticated, statistical approaches and state of the art technology. You will build and refine our tools/techniques and engage w/internal stakeholders across the organization to improve our products &amp; services.</p><p>\\nImplementing solutions is critical for success. You will do problem identification, solution proposal &amp; presentation to a wide variety of management &amp; technical audiences. This challenging career requires you to work on multiple concurrent projects in a community setting, developing yourself and others, and advancing data science both at State Farm and externally.</p><p><b>\\nS</b><b>kills &amp; Professional Experience</b></p><ul><li> Develop hypotheses, design experiments, and test feasibility of proposed actions to determine probable outcomes using a variety of tools &amp; technologies</li><li> Masters, other advanced degrees, or five yearsâ€™ experience in an analytical field such as data science quantitative marketing, statistics, operations research, management science, industrial engineering, economics, etc. or equivalent practical experience preferred.</li><li> Experience with SQL, Python, R, Java, SAS or MapReduce, SPARK</li><li> Experience with unstructured data sets: text analytics, image recognition etc.\\n</li><li> Experience working w/numerous large data sets/data warehouses &amp; ability to pull from such data sets using relevant programs &amp; coding including files, RDBMS &amp; Hadoop based storage systems</li><li> Knowledge in machine learning methods including at least one of the following: Time series analysis, Hierarchical Bayes; or learning techniques such as Decision Trees, Boosting, Random Forests.</li><li> Excellent communication skills and the ability to manage multiple diverse stakeholders across businesses &amp; leadership levels.</li><li> Exercise sound judgment to diagnose &amp; resolve problems within area of expertise</li><li> Familiarity with CI/CD development methods, Git and Docker a plus</li></ul><p>\\nMultiple location opportunity. Locations offered are: Atlanta, GA, Bloomington, IL, Dallas, TX and Phoenix, AZ</p><p>\\nRemote work option is not available.</p><p>\\nThere is no sponsorship for an employment visa for the position at this time.</p><p></p><br/>\\n<p>\\n#LI-MV1</p><p></p><p><br/>\\nSFARM</p><p>\\nPM18</p></div><p></p></div>', 'Text Analytics']\n",
      "\n",
      "COMMIT\n",
      "RELEASE CONNECTION\n"
     ]
    }
   ],
   "source": [
    "starts = list(range(10, 1000, 10))\n",
    "requests = 0\n",
    "start = time.time()\n",
    "\n",
    "baseurl = 'https://www.indeed.com/'\n",
    "\n",
    "nlp_jobs = []\n",
    "for start in starts:\n",
    "    my_urls = ('https://www.indeed.com/jobs?q=\"text+analytics\"&start=' + str(start),)\n",
    "    my_url = my_urls[0]\n",
    "    for my_url in my_urls:\n",
    "        uClient = urlopen(my_url)\n",
    "        html_input = uClient.read()\n",
    "        uClient.close()\n",
    "        soup = BeautifulSoup(html_input, \"html.parser\")\n",
    "        cards = soup.findAll('div', {'class':'jobsearch-SerpJobCard'})\n",
    "        it = iter(cards)\n",
    "        next(it) # ads\n",
    "        next(it) # ads\n",
    "        #next(it)\n",
    "        for curr in it: \n",
    "            try:\n",
    "                link = curr.find('h2').find('a', href=True)['href']\n",
    "            except:\n",
    "                pass\n",
    "            with urlopen(baseurl + link) as uClient:\n",
    "                list_url = uClient.read()\n",
    "            listing = BeautifulSoup(list_url, 'html.parser')\n",
    "            title = listing.find('h3', \n",
    "                            {'class': 'icl-u-xs-mb--xs icl-u-xs-mt--none jobsearch-JobInfoHeader-title'})\n",
    "            if not title:\n",
    "                    print('missing content @ ' + baseurl + link)\n",
    "            body = listing.find('div', \n",
    "                            {'class': 'jobsearch-JobComponent-description icl-u-xs-mt--md'}\n",
    "                            )\n",
    "            if not body:\n",
    "                print('missing content @ ' + baseurl + link) \n",
    "            requests += 1\n",
    "            sleep(randint(3,5))\n",
    "            end = time.time()\n",
    "            #print(\"Done in\", end, \"seconds\")\n",
    "            print('Request: {}; Frequency: {} requests/s'.format(requests, requests/end))\n",
    "            clear_output(wait = True)\n",
    "            with db_session:\n",
    "                Job(title=str(title), \n",
    "                job_description=str(body), \n",
    "                job_class='Text Analytics')\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(nlp_jobs[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
