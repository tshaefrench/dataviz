{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import urljoin\n",
    "page = requests.get('https://www.indeed.com/jobs?q=%22Natural+Language+Processing%22+or+%22NLP%22&fromage=last&start=')\n",
    "from time import sleep\n",
    "import time\n",
    "from random import randint\n",
    "from pony_main import *\n",
    "from pony.orm import *\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "from IPython.display import clear_output\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'pony_main' from '/Users/tiffanyfrench/pony_main.py'>\n"
     ]
    }
   ],
   "source": [
    "print(pny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with pny.db_session:\n",
    "    #pny.title = \"NLP Engineer\",\n",
    "    #pny.job_description = 'job things'\n",
    "    #pny.job_class = 'Natural Language Processing'\n",
    "    #set_sql_debug(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET CONNECTION FROM THE LOCAL POOL\n",
      "BEGIN IMMEDIATE TRANSACTION\n",
      "INSERT INTO \"Job\" (\"title\", \"job_description\", \"job_class\") VALUES (?, ?, ?)\n",
      "['<h3 class=\"icl-u-xs-mb--xs icl-u-xs-mt--none jobsearch-JobInfoHeader-title\">Data Science Associate</h3>', '<div class=\"jobsearch-JobComponent-description icl-u-xs-mt--md\"><div><p><b>ZS</b> is the world’s largest consulting firm focused exclusively on improving business performance through sales and marketing consulting solutions, from customer insights and strategy to analytics, operations and technology. Together, we design and implement strategies that lead to greater market share, more competitive operations and increased use of today’s latest technologies. From our worldwide offices, ZS professionals draw on deep industry and domain expertise to deliver impact where it matters for clients. We are particularly known for our expertise in the pharmaceutical and health care sectors, yet work across a range of industries.</p><p><b>\\nZS\\' Business Consulting group</b> delivers solutions to a broad spectrum of sales and marketing challenges. We also help our clients transform their sales and marketing strategies and organizations to improve their effectiveness. Our recommendations and solutions are based in rigorous research and analysis underpinned by deep expertise and thought leadership across the demand generation process.</p><p><b>\\nDATA SCIENCE ASSOCIATE\\n</b></p><p>Data Science Associates (DSAs) design, develop and execute algorithmic, statistical and/or machine learning techniques on large, complex, structured and unstructured data sets (including big data) to help clients make better fact-based decisions. DSAs will deliver client impact through:</p><p></p><br/>\\n<ul><li>\\nCollaborate with team leadership on research and development of new algorithms</li><li>\\nCustomization of general-purpose algorithms to specific context-rich client situations</li><li>\\nContribution to development of the ZS point of view in AI/ML/data science space</li></ul><p></p><br/>\\n<p><b>\\nResponsibilities:</b></p><ul><li>\\nInvestigate and develop rigorous analytical frameworks to address client problems</li><li>\\nEffectively work with a variety of different data – structured vs. unstructured, sparse vs. big data – to perform modeling and analysis</li><li>\\nDevelop advanced algorithms that solve problems of large dimensionality in a computationally efficient and statistically effective manner</li><li>\\nExecute statistical and machine learning techniques (e.g. supervised learning, unsupervised learning, reinforcement learning) on data sets to identify trends, figures and other relevant information</li><li>\\nCollaborate with clients and other ZS stakeholders to effectively integrate and communicate analysis findings</li><li>\\nEvaluate emerging datasets and technologies that may contribute to our analytical offerings</li></ul><p><b>\\nQualifications:</b></p><ul><li>\\nMaster’s Degree in Data Science, Computer Science or Statistics with strong academic performance in analytic and quantitative coursework required</li><li>\\nKnowledge of advanced analytics concepts and algorithms (e.g. machine learning, statistical learning, Bayesian methods, neural networks, optimization, natural language processing, etc.)</li><li>\\nDemonstrates proficiency in programming languages such as R/Python</li><li>\\nExposure to tools/platforms (e.g. Hadoop eco system and database systems)</li><li>\\nAgile project planning and project management skills</li><li>\\nExcellent oral and written communication skills</li><li>\\nStrong attention to detail, with a research-focused mindset</li><li>\\nExcellent critical thinking and problem-solving skills</li><li>\\nAptitude for, and enjoyment of working in teams</li><li>\\nHigh motivation, good work ethic and maturity<br/>\\n</li></ul><p>\\nZS is a global consulting firm; fluency in English is required, additional fluency in at least one European or Asian language is desirable.</p><p>\\nCandidates must possess work authorization for their intended country of employment. An on-line application, including a cover letter expressing interest and a full set of transcripts (official or unofficial), is required to be considered.</p><p>\\nZS offers a competitive compensation package with salary and bonus incentives, complete medical/dental/life insurance programs and retirement savings benefits. We are an Equal Opportunity Employer.</p><p><b>\\nNO AGENCY CALLS, PLEASE.</b></p><p></p><br/>\\n<p><b>\\nConnect with ZS on social media:</b></p><ul><li>\\nLike ZS Careers on <b>Facebook</b></li><li>\\nFollow ZS Careers on <b>Twitter</b> and <b>Instagram</b></li><li>\\nFollow ZS on <b>LinkedIn</b> for more job opportunities</li><li>\\nSubscribe to the ZS <b>YouTube</b> channel</li><li>\\nExplore the <b>Life at ZS</b> blog</li></ul><p>\\nZS has been recognized globally for its expertise in consulting and its flexible work environment. View <b>ZS’s accolades</b>.</p></div></div>', 'Natural Language Processing']\n",
      "\n",
      "COMMIT\n",
      "RELEASE CONNECTION\n"
     ]
    }
   ],
   "source": [
    "starts = list(range(440, 1000, 10))\n",
    "requests = 0\n",
    "start = time.time()\n",
    "\n",
    "baseurl = 'https://www.indeed.com'\n",
    "\n",
    "nlp_jobs = []\n",
    "for start in starts:\n",
    "    my_urls = ('https://www.indeed.com/jobs?q=%22Natural+Language+Processing%22+or+%22NLP%22&fromage=last&start=' + str(start),)\n",
    "    my_url = my_urls[0]\n",
    "    for my_url in my_urls:\n",
    "        uClient = urlopen(my_url)\n",
    "        html_input = uClient.read()\n",
    "        uClient.close()\n",
    "        soup = BeautifulSoup(html_input, \"html.parser\")\n",
    "        cards = soup.findAll('div', {'class':'jobsearch-SerpJobCard'})\n",
    "        it = iter(cards)\n",
    "        next(it) # ads\n",
    "        next(it) # ads\n",
    "        for curr in it: \n",
    "\n",
    "            #title = curr.find('h3', {'class': 'icl-u-xs-mb--xs icl-u-xs-mt--none jobsearch-JobInfoHeader-title'})\n",
    "            try:\n",
    "                link = curr.find('h2').find('a', href=True)['href']\n",
    "            except:\n",
    "                print('missing content @' + baseurl + str('href')) \n",
    "            #if not link:\n",
    "                #\n",
    "            #elif not curr:\n",
    "                #print('missing content @' + baseurl + str('href'))\n",
    "            with urlopen(baseurl + link) as uClient:\n",
    "                list_url = uClient.read()\n",
    "            listing = BeautifulSoup(list_url, 'html.parser')\n",
    "            title = listing.find('h3', \n",
    "                            {'class': 'icl-u-xs-mb--xs icl-u-xs-mt--none jobsearch-JobInfoHeader-title'})\n",
    "            if not title:\n",
    "                    print('missing content @ ' + baseurl + link)\n",
    "            body = listing.find('div', \n",
    "                            {'class': 'jobsearch-JobComponent-description icl-u-xs-mt--md'}\n",
    "                            )\n",
    "            if not body:\n",
    "                print('missing content @ ' + baseurl + link)\n",
    "            requests += 1\n",
    "            sleep(randint(5,7))\n",
    "            end = time.time()\n",
    "            #print(\"Done in\", end, \"seconds\")\n",
    "            print('Request: {}; Frequency: {} requests/s'.format(requests, requests/end))\n",
    "            clear_output(wait = True)\n",
    "            with db_session:\n",
    "                Job(title=str(title), \n",
    "                job_description=str(body), \n",
    "                job_class='Natural Language Processing')\n",
    "            #posting = {\n",
    "                #'title':title,\n",
    "                #'job_description':body\n",
    "                #}\n",
    "            #nlp_jobs.append(posting)\n",
    "            #pony as a context manager\n",
    "            #def add_job(title, job_description, job_class):\n",
    "                #with pny.db_session:\n",
    "                    #title = title,\n",
    "                    #job_description = body,\n",
    "                    #job_class = 'Natural Language Processing'\n",
    "                #set_sql_debug(True)\n",
    "            #@db_session\n",
    "            #def add_job(title, job_description, job_class):\n",
    "                #d = Job()\n",
    "                #d.title = title\n",
    "                #d.job_description = body\n",
    "                #d.job_class = 'Natural Language Processing'\n",
    "            #commit()       \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(nlp_jobs[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
