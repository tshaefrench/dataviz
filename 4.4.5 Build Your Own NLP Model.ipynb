{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import state_union, stopwords\n",
    "from collections import Counter\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#state_union.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's analyze Eisenhower and Kennedy\n",
    "eisenhower = state_union.raw('1953-Eisenhower.txt')\n",
    "kennedy = state_union.raw('1962-Kennedy.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SpaCy\n",
    "nlp = spacy.load('en')\n",
    "eisenhower_doc = nlp(eisenhower)\n",
    "kennedy_doc = nlp(kennedy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(PRESIDENT, DWIGHT, D., EISENHOWER, 'S)</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(ANNUAL, MESSAGE, TO, THE, CONGRESS, ON, THE, ...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Mr., President, ,, Mr., Speaker, ,, Members, ...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(I, welcome, the, honor, of, appearing, before...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(It, is, manifestly, the, joint, purpose, of, ...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0           1\n",
       "0            (PRESIDENT, DWIGHT, D., EISENHOWER, 'S)  Eisenhower\n",
       "1  (ANNUAL, MESSAGE, TO, THE, CONGRESS, ON, THE, ...  Eisenhower\n",
       "2  (Mr., President, ,, Mr., Speaker, ,, Members, ...  Eisenhower\n",
       "3  (I, welcome, the, honor, of, appearing, before...  Eisenhower\n",
       "4  (It, is, manifestly, the, joint, purpose, of, ...  Eisenhower"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group into sentences.\n",
    "eisenhower_sents = [[sent, 'Eisenhower'] for sent in eisenhower_doc.sents]\n",
    "kennedy_sents = [[sent, \"Kennedy\"] for sent in kennedy_doc.sents]\n",
    "\n",
    "# Combine the sentences from the two novels into one data frame.\n",
    "sentences = pd.DataFrame(eisenhower_sents + kennedy_sents)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eisenhower speech length: 7922\n",
      "Kennedy speech length: 7711\n"
     ]
    }
   ],
   "source": [
    "# how long are their speeches?\n",
    "print('Eisenhower speech length:', len(eisenhower_doc))\n",
    "print('Kennedy speech length:', len(kennedy_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRESIDENT DWIGHT D. EISENHOWER'S ANNUAL MESSAGE TO THE CONGRESS ON THE STATE OF THE UNION\n",
      " \n",
      "February 2, 1953\n",
      "\n",
      "Mr. President, Mr. Speaker, Members of the Eighty-third Congress:\n",
      "I welcome the honor of appearing before you to deliver my first message to the Congress.\n",
      "It is manifestly the joint purpose of the congressional leadership and of this administration to justify the summons to governmental responsibility issued last November by the American people. The grand labors of this leadership will involve:\n",
      "Application of America's influence in\n",
      "PRESIDENT JOHN F. KENNEDY'S ANNUAL ADDRESS TO A JOINT SESSION OF CONGRESS ON THE STATE OF THE UNION\n",
      " \n",
      "This week we begin anew our joint and separate efforts to build the American future. But, sadly, we build without a man who linked a long past with the present and looked strongly to the future. \"Mister Sam\" Rayburn is gone. Neither this House nor the Nation is the same without him.\n",
      "Members of the Congress, the Constitution makes us not rivals for power but partners for progress. We\n"
     ]
    }
   ],
   "source": [
    "# check excerpts for any cleaning needed\n",
    "print(eisenhower_doc[:100])\n",
    "print(kennedy_doc[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 2000 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(2000)]\n",
    "    \n",
    "\n",
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 500 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'spacy.tokens.doc.Doc' and 'spacy.tokens.doc.Doc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c207329da7e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Combine bags to create a set of unique words.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcommon_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meisenhower_doc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mkennedy_doc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'spacy.tokens.doc.Doc' and 'spacy.tokens.doc.Doc'"
     ]
    }
   ],
   "source": [
    "# Set up the bags.\n",
    "eisenhowerwords = bag_of_words(eisenhower_doc)\n",
    "kennedywords = bag_of_words(kennedy_doc)\n",
    "\n",
    "# Combine bags to create a set of unique words.\n",
    "common_words = set(eisenhower_doc + kennedy_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bow features \n",
    "bow = bow_features(sentences, common_words)\n",
    "bow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentences\n",
    "eisenhower = state_union.sents('1953-Eisenhower.txt')\n",
    "kennedy = state_union.sents('1962-Kennedy.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists\n",
    "eisenhower_list = [\" \".join(sent) for sent in eisenhower]\n",
    "kennedy_list = [\" \".join(sent) for sent in kennedy]\n",
    "joined = eisenhower_list + kennedy_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
